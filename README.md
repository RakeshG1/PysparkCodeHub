# PysparkCodeHub

## General Info

    - Java is needed to be installed as prerequisite, to execute pyspark code
    - Currently this repo pyspark code is tested in Ubuntu environment

## RDD : Resilient Distributed Dataset

    - It is schema less
    - It is low level abstraction requiring writing functional code to manipulate data

## Spark Data Frame

    - It supports schema like tabular dataset
    - Data manipulation on data frame is easier
